---
layout: post
title: Another definition of AGI
---

For many decades the standard benchmark that researchers used to evaluate whether a computer program was intelligent or not was the Turing Test. The test was very simple, a person and someone else (a computer or another person) would sit at both ends of a screen and would interact with each other via messages. Then the person would have to guess if they are talking to a computer or to another person.

![Kara from Detroit: Become Human](/images/Kara-1.webp)

For many years that was a dream. No system was even remotely smart enough to overcome that test. And then in a few years we blew past that level of performance. It’s becoming almost impossible to know when a voice is real or synthetically generated. And sometimes it’s even hard to know when a video of a person is real or not. In a few short years it will be essentially impossible to trust any digital media.

By that definition we have already reached AGI (artificial general intelligence), in the sense that an average human just cannot differentiate. Notice the mention of average human. The definition was never “can a world-class expert identify the machine or human” or “can a team of elite engineers and scientists indicate whether it’s a machine or a human”. The definition was can an average human detect it.

I never liked that definition. So here is another one, an AGI is a system that can independently perform economically useful work in an equivalent way that an average human can. 

So I don’t mean a computer program that can make money. We’ve had many computer programs that generate millions or billions of dollars. I mean a system that can perform similar jobs than an average human can. An uber delivery driver (self-driving cars are getting there), a seller at a clothing store (robotics are not mature enough to fold clothes and move items), a bookkeeper (LLMs can probably already do this job already, they can read PDFs and edit spreadsheets). But in general I don’t think we are quite there yet. There is a bit of learning that happens in humans, over years of living in a physical world, formal and informal education and on-the-job training. LLMs can’t do that yet.

We are not far off though. And here is why I think the definition is useful. Because it makes it obvious that when LLMs or other types of still-to-be-made systems reach that level we will need as a society to rethink how people will make a living. Humans lived for many years as hunter-gatherers, simply living off nature. Then agriculture was discovered and we created villages, and jobs. And the way to make a living for most people since then was to work (for themselves or others) to get money or resources to trade. That model of human existence is ending very soon.
